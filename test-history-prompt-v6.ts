/**
 * Test Script for V6 History Prompt (Two-Step Grounded Approach)
 *
 * V6 uses two-step extraction process:
 * - STEP 1: Extract all visible facts as bullet points
 * - STEP 2: Write questions ONLY from those extracted facts
 * - Forces Gemini to explicitly list what it sees before generating questions
 */

import { GoogleGenerativeAI } from '@google/generative-ai'
import { readFileSync, writeFileSync, readdirSync } from 'fs'
import { join } from 'path'
import dotenv from 'dotenv'

dotenv.config({ path: '.env.local' })

const GEMINI_API_KEY = process.env.GEMINI_API_KEY
if (!GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY not found in .env.local')
}

const genAI = new GoogleGenerativeAI(GEMINI_API_KEY)

/**
 * V6 TWO-STEP PROMPT - Forces explicit fact extraction before question generation
 */
function getTwoStepHistoryPrompt(grade: number = 8): string {
  return `SYSTEM INSTRUCTION (prepend this before any user content):
You must treat the uploaded textbook images as your *only factual source*.
Do not rely on your general history knowledge. Use only the information explicitly extracted in Step 1.
If something is not visible in the textbook pages, skip it.

---

## üéì Task
Create a **history exam for grade ${grade} students** based *only* on the uploaded textbook pages.

---

## üîç STEP 1 ‚Äî EXTRACT FACTS FIRST (no questions yet)
List all the **facts visible** in the textbook images, such as:
- key dates and what happened on each date
- names of people or groups mentioned
- historical terms explicitly defined
- cause‚Äìeffect or consequence statements

Write them as bullet points.

You must not add information that isn't clearly visible in the text or timeline.
If you cannot read a part, skip it.

---

## ‚úçÔ∏è STEP 2 ‚Äî WRITE QUESTIONS ONLY FROM THOSE FACTS
Use only the facts you listed in Step 1 to create the questions.

Follow this exact structure:
- 2 terminology questions ("What does X mean?")
- 6 event questions ("What happened / when / where?")
- 4 cause‚Äìconsequence questions ("Why / what resulted?")
- 3 people questions ("Who / what did they do?")
‚Üí Total = 15 questions

Every question must connect to a fact from Step 1.
If a person, date, or event wasn't listed, don't use it.

---

## üéØ ADDITIONAL RULES

### Language
- Auto-detect textbook language and use it everywhere.
- No translation, no mixing.

### Style
- Write like a teacher talking to students.
- Never mention "the text", "material", or "chapter".
- Use natural, clear sentences.

### Terminology Rule
- Only ask meanings of *specialized historical terms* (e.g. hyperinflation, civil war).
- Never ask about common words (independence, democracy, war, peace).

### Validation
- Exactly 2 terminology questions.
- No generic vocabulary or invented names.
- All 15 questions grounded, clear, and answerable from the textbook pages.

---

## üß© JSON OUTPUT

{
  "questions": [
    {
      "id": 1,
      "type": "multiple_choice",
      "question": "[Natural question in source language]",
      "options": ["A", "B", "C", "D"],
      "correct_answer": "[Exact match from options]",
      "explanation": "[1‚Äì2 sentences, factual and concise]"
    }
  ],
  "summary": {
    "introduction": "[100‚Äì200 words ‚Äì introduce the historical topic from the text]",
    "key_concepts": "[250‚Äì400 words ‚Äì main events, causes, results]",
    "examples_and_applications": "[150‚Äì250 words ‚Äì help students understand significance]",
    "summary_conclusion": "[80‚Äì150 words ‚Äì wrap up clearly]",
    "total_word_count": [number],
    "language": "[ISO 639-1 code]"
  }
}

---

## ‚ö†Ô∏è FINAL CHECKLIST
‚úÖ 15 total questions
‚úÖ 2 terminology exactly
‚úÖ No "material/text" references
‚úÖ No invented facts or external info
‚úÖ All questions linked to Step 1 facts
‚úÖ Natural, student-friendly phrasing`
}

function loadTestImages(folderPath: string): Array<{ inlineData: { data: string; mimeType: string } }> {
  const imageParts: Array<{ inlineData: { data: string; mimeType: string } }> = []

  try {
    const files = readdirSync(folderPath)
    const imageFiles = files.filter(f => f.match(/\.(jpg|jpeg|png|webp|heic)$/i))

    console.log(`üìÅ Found ${imageFiles.length} images in ${folderPath}`)

    for (const file of imageFiles) {
      const filePath = join(folderPath, file)
      const imageBuffer = readFileSync(filePath)
      const base64 = imageBuffer.toString('base64')

      const ext = file.toLowerCase()
      let mimeType = 'image/jpeg'
      if (ext.endsWith('.png')) mimeType = 'image/png'
      else if (ext.endsWith('.webp')) mimeType = 'image/webp'
      else if (ext.endsWith('.heic')) mimeType = 'image/heic'

      imageParts.push({ inlineData: { data: base64, mimeType } })
      console.log(`  ‚úì Loaded: ${file}`)
    }

    return imageParts
  } catch (error) {
    console.error(`‚ùå Error loading images:`, error)
    throw error
  }
}

async function generateTwoStepHistoryExam(imageParts: Array<{ inlineData: { data: string; mimeType: string } }>) {
  console.log(`\nüß™ Testing V6 Two-Step Grounded Prompt with ${imageParts.length} images...\n`)

  const model = genAI.getGenerativeModel({
    model: 'gemini-2.0-flash-exp',
    generationConfig: {
      temperature: 0,
      responseMimeType: 'application/json'
    }
  })

  const prompt = getTwoStepHistoryPrompt(8)
  const startTime = Date.now()

  try {
    const result = await model.generateContent([prompt, ...imageParts])
    const duration = Date.now() - startTime
    const response = result.response
    const text = response.text()

    console.log(`‚úÖ Generation completed in ${(duration / 1000).toFixed(2)}s\n`)

    let parsedResponse
    try {
      parsedResponse = JSON.parse(text)
    } catch (parseError) {
      console.error('‚ùå Failed to parse JSON response')
      writeFileSync('test-output-history-v6-raw.txt', text)
      throw parseError
    }

    // Analyze
    if (parsedResponse.questions) {
      const questions = parsedResponse.questions
      console.log(`üìù Generated ${questions.length} questions\n`)

      let terminology = 0, events = 0, causes = 0, people = 0
      const terminologyQuestions: string[] = []

      questions.forEach((q: any) => {
        const text = q.question.toLowerCase()
        if (text.includes('mit√§ tarkoittaa') || text.includes('mit√§ tarkoitti') ||
            text.includes('what does') || text.includes('what is')) {
          terminology++
          terminologyQuestions.push(q.question)
        } else if (text.includes('miksi') || text.includes('why') ||
                   text.includes('seurauksi') || text.includes('consequence')) {
          causes++
        } else if (text.includes('kuka') || text.includes('ketk√§') || text.includes('who')) {
          people++
        } else {
          events++
        }
      })

      console.log('üìà Question Distribution:')
      console.log(`  Terminology: ${terminology} (target: EXACTLY 2)`)
      console.log(`  Events: ${events} (target: 6)`)
      console.log(`  Causes/Results: ${causes} (target: 4)`)
      console.log(`  People: ${people} (target: 3)`)
      console.log(`  Total: ${questions.length}/15\n`)

      if (terminology === 2) {
        console.log('  ‚úÖ PERFECT: Exactly 2 terminology questions!')
      } else {
        console.log(`  ‚ö†Ô∏è  Got ${terminology} terminology questions (target: 2)`)
      }

      if (terminologyQuestions.length > 0) {
        console.log('\nüìö Terminology Questions:')
        terminologyQuestions.forEach((q, idx) => console.log(`  ${idx + 1}. ${q}`))
      }

      console.log('\nüìã All Questions:')
      questions.forEach((q: any, idx: number) => {
        console.log(`  ${idx + 1}. ${q.question}`)
      })
    }

    const output = {
      test_metadata: {
        timestamp: new Date().toISOString(),
        version: 'v6-two-step-grounded',
        prompt_source: 'V6 - Two-Step Fact Extraction',
        model: 'gemini-2.0-flash-exp',
        temperature: 0,
        duration_ms: duration
      },
      prompt_used: prompt,
      gemini_response: parsedResponse
    }

    writeFileSync('test-output-history-v6.json', JSON.stringify(output, null, 2))
    console.log(`\nüíæ Saved to: test-output-history-v6.json\n`)

  } catch (error) {
    console.error('‚ùå Error:', error)
    throw error
  }
}

async function main() {
  console.log('üèõÔ∏è  V6 HISTORY PROMPT TESTER (Two-Step Grounded Approach)')
  console.log('=========================================================\n')

  try {
    const imageParts = loadTestImages('assets/images/history_8th_compr')
    await generateTwoStepHistoryExam(imageParts)
    console.log('‚úÖ Test completed!\n')
  } catch (error) {
    console.error('\n‚ùå Test failed:', error)
    process.exit(1)
  }
}

main()
